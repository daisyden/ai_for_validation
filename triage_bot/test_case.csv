test.distributed.fsdp.test_fsdp_fine_tune.py,test_hooks_multi_traversal_xpu,failed,AssertionError: Scalars are not close!
test_distributed_checkpoint.py,test_distributed_checkpoint_state_dict_type0_xpu,failed,EXCEPTION: RECV entry failed. atl_status: FAILURE
test/distributed/_composable/fsdp/test_fully_shard_comm.py,TestFullyShardCommunication.test_set_reduce_scatter_divide_factor,failed,ValueError: Cannot use ReduceOp.PREMUL_SUM with XCCL
test_fsdp_core.py ,test_transformer_no_grad_mixed_precision_True_xpu,failed,self._join_processes(fn) \nFile ""/home/sdp/miniforge3/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py"", line 845, in _join_processes\n  self._check_return_codes(elapsed_time) \n  File ""/home/sdp/miniforge3/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py"", line 902, in _check_return_codes \n self.assertEqual( \n File ""/home/sdp/miniforge3/envs/xpu_op_/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py"", line 4094, in assertEqual \nraise error_metas.pop()[0].to_error(  # type: ignore[index] \n AssertionError: Scalars are not equal!
test_ops_xpu.py ,test_compare_cpu_argmin_xpu_int64,failed,AssertionError: Scalars are not close!
test_ops_xpu.py ,test_compare_cpu_nn_functional_interpolate_bicubic_xpu_float64,failed,RuntimeError: Non-uniform work-groups are not supported by the target device
test_ops_xpu.py,test_compare_cpu_grid_sampler_2d_xpu_float64,failed,Fatal Python error: Illegal instruction
test_meta_xpu.py::TestMetaXPU,test_dispatch_meta_outplace_nn_functional_scaled_dot_product_attention_xpu_bfloat16,failed,"RuntimeError: output 1: meta disagrees with real impl:
aten._scaled_dot_product_fused_attention_overrideable.default(tensor(..., device='meta', size=(4, 4, 3, 8)) stride=(96, 24, 8, 1),   tensor(..., device='meta', size=(4, 4, 6, 8)) stride=(192, 48, 8, 1),  tensor(..., device='meta', size=(4, 4, 6, 8)) stride=(192, 48, 8, 1),  None,  0.0,  True, ) = ( (tensor(..., device='meta', size=(4, 4, 3, 8)) stride=(96, 24, 8, 1), tensor(..., device='meta', size=(4, 4, 3)) stride=(12, 3, 1), None, None, 3, 6, tensor(..., device='meta', size=(), dtype=torch.int64) stride=(), tensor(..., device='meta', size=(), dtype=torch.int64) stride=(), None)) for element 1, was torch.Size([4, 4, 3]) but real shape was torch.Size([])"
test_ops_xpu.py::TestCommonXPU,test_dtypes_view_as_complex_xpu,failed,RuntimeError: value cannot be converted to type float without overflow
test_ops_xpu.py,test_dtypes_fft_fft2_xpu,failed,The following dtypes did not work in backward but are listed by the OpInfo: {torch.bfloat16}.
test.distributed._composable.fsdp.test_fully_shard_compile.TestFullyShardCompile,test_compiled_autograd_ctx,failed,torch._dynamo.exc.Unsupported: Attempted to call function marked as skipped
test/distributed/test_inductor_collectives.py::TestCollectivesInductor,test_dynamo_rewrite_dist_all_gather,failed,Fatal Python error: Segmentation fault
test/distributed/tensor/parallel/test_micro_pipeline_tp.py::MicroPipelineTPTest,test_fuse_matmul_reduce_scatter_A_dims_3_scatter_dim_2,failed,NotImplementedError: The operator 'symm_mem::fused_matmul_reduce_scatter' is not currently implemented for the XPU device
test/distributed/test_c10d_object_collectives.py::TestObjectCollectivesCPU,test_gather_object_cpu,failed,RuntimeError: Process 0 terminated or timed out after 300.09047198295593 seconds
test/distributed/_tools/test_fsdp2_mem_tracker.py::TestTrackerFullyShard1DTrainingCompose,test_tracker_with_activation_checkpointing,failed,RuntimeError: oneCCL: coll_param.cpp:455 validate: EXCEPTION: average operation is not supported for the scheduler pathRuntimeError: oneCCL: coll_param.cpp:455 validate: EXCEPTION: average operation is not supported for the scheduler path
test_distributions_xpu.py::TestDistributionsXPU,test_gamma_gpu_sample_xpu,failed,"AssertionError: -0.06743384440339613 not less than -0.259 : Gamma(alpha=1.0, beta=0.1).sample() is biased:"

third_party.torch-xpu-ops.test.xpu.test_linalg_xpu.TestLinalgXPU , test_gemm_bias_offline_tunableop_xpu_bfloat16 , failed , AssertionError: Torch not compiled with CUDA enabled
 third_party.torch-xpu-ops.test.xpu.test_linalg_xpu.TestLinalgXPU , test_gemm_bias_tunableop_xpu_bfloat16 , failed , AttributeError: module &#x27;torch._C&#x27; has no attribute &#x27;_cuda_tunableop_enable&#x27; 
 third_party.torch-xpu-ops.test.xpu.test_linalg_xpu.TestLinalgXPU , test_scaled_gemm_offline_tunableop_xpu_float8_e4m3fnuz , failed , AssertionError: Torch not compiled with CUDA enabled 
 third_party.torch-xpu-ops.test.xpu.test_linalg_xpu.TestLinalgXPU , test_scaled_gemm_tunableop_xpu_float8_e5m2fnuz , failed , AttributeError: module &#x27;torch._C&#x27; has no attribute &#x27;_cuda_tunableop_enable&#x27; 
 third_party.torch-xpu-ops.test.xpu.test_transformers_xpu.TestTransformersXPU , test_multiheadattention_fastpath_attn_mask_attn_mask_dim_2_key_padding_mask_dim_2_bool_xpu , failed , RuntimeError: output 1: meta disagrees with real impl 
 third_party.torch-xpu-ops.test.xpu.test_transformers_xpu.TestTransformersXPU , test_transformerencoder_fastpath_use_torchscript_False_enable_nested_tensor_False_use_autocast_False_d_model_12_xpu , failed , RuntimeError: output 1: meta disagrees with real impl 
 third_party.torch-xpu-ops.test.xpu.test_transformers_xpu.TestTransformersXPU , test_transformerencoder_fastpath_use_torchscript_False_enable_nested_tensor_False_use_autocast_True_d_model_12_xpu , failed , RuntimeError: output 1: meta disagrees with real impl 
third_party.torch-xpu-ops.test.xpu.test_meta_xpu.TestMetaXPU,test_dispatch_meta_outplace_norm_fro_xpu_bfloat16,failed,RuntimeError: output 0: meta disagrees with real impl
third_party.torch-xpu-ops.test.xpu.test_meta_xpu.TestMetaXPU,test_dispatch_meta_outplace_norm_fro_xpu_complex128,failed,RuntimeError: output 0: meta disagrees with real impl
third_party.torch-xpu-ops.test.xpu.test_meta_xpu.TestMetaXPU,test_dispatch_meta_outplace_norm_fro_xpu_complex64,failed,RuntimeError: output 0: meta disagrees with real impl
test_ops_xpu.py::TestCommonXPU,test_compare_cpu_cosh_xpu_complex128,failed,AssertionError: Tensor-likes are not close! 
TestPoolingNNDeviceTypeXPU.test_MaxUnpool_index_errors_case1_xpu,test_MaxUnpool_index_errors_case1_xpu,failed,AssertionError: 'Assertion `maxind >= 0 && maxind < outputImageSize` failed' not found in '\nAssertHandler::printMessage\n' : The expected error was not found
nn\test_pooling_xpu.py::TestPoolingNNDeviceTypeXPU,test_maxpool3d_non_square_backward_xpu,failed,RuntimeError: UR error
test_native_mha_xpu.py::TestMHADeviceTypeXPU,test_native_multihead_attention_xpu_float16,failed,AssertionError: Tensor-likes are not close!
test_unary_ufuncs_xpu.py::TestUnaryUfuncsXPU,test_reference_numerics_extremal_exp_xpu_complex64,failed,AssertionError: Tensor-likes are not close!
test_autograd_xpu.py::TestAutograd,test_multi_grad_all_hooks,failed,RuntimeError: Ninja is required to load C++ extensions
test_autograd_xpu.py::TestAutogradDeviceTypeXPU,test_rnn_backward_to_input_but_not_parameters_xpu,failed,NotImplementedError: Could not run 'aten::_thnn_fused_lstm_cell' with arguments from the 'CPU' backend
test_unary_ufuncs_xpu.py::TestUnaryUfuncsXPU,test_reference_numerics_small_acos_xpu_complex32,failed,AssertionError: Tensor-likes are not close!
test_ops_xpu.py::TestCommonXPU,test_compare_cpu_nn_functional_softshrink_xpu_bfloat16,failed,AssertionError: Tensor-likes are not close!
NA,NA,failed,RuntimeError: Native API failed. Native API returns: -36 (PI_ERROR_INVALID_QUEUE) -36 (PI_ERROR_INVALID_QUEUE)
test_modules_xpu.py::TestModuleXPU,test_non_contiguous_tensors_nn_LazyConv3d_xpu_float32,failed,AssertionError: Tensor-likes are not close! \nMismatched elements: 540 / 640 (84.4%)\n"Greatest absolute difference: 0.00005278512835502625 at index (1, 45) (up to 1e-05 allowed)"\n"Greatest relative difference: 0.0000021018216609955 at index (8, 26) (up to 1.3e-06 allowed)"
torch-xpu-ops.test.xpu.test_linalg_xpu.TestLinalgXPU,test_tensordot_out_kernel_errors_with_autograd_xpu_float32,failed,AssertionError: "the 'out' tensor was specified and requires gradients" does not match "cannot resize variables that require grad"
torch-xpu-ops.test.xpu.test_meta_xpu.TestMetaXPU,test_dispatch_meta_outplace_nn_functional_conv2d_xpu_bfloat16,failed,NotImplementedError: Could not run 'aten::_conv_depthwise2d' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, o    r was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_conv_depthwise2d' is only available for these backends: [XPU, Meta, Backend    Select, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, Autogra    dMAIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastMTIA, AutocastMAIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradW    rapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].
test_decomp.py::TestDecompXPU,test_comprehensive_nn_functional_cross_entropy_xpu_bfloat16,failed,RuntimeError: Difference from float64 is larger with decomposition nll_loss_backward.default than original on output 0. Original max diff: 0.0, Decomp max diff: 0.4765625
